Modules include: shared memory space, scheduler, networking channel.

Relationship: At first, we have processes that make a system call down into the “kernel”. The “kernel” provides a classifier associated with a channel. The channel which is a single producer/single consumer queue transfers packets to the application thread. It saves much processes in the traditional network stack and removes the lock and cache-line contention. Also, in this progress OSv allows only one thread thread to access the data which is stored in a single address space. Compared to the traditional thread scheduler, OSv’s thread scheduler does not use spin-locks and sleeping mutex. Based on the fairness criteria of threads on the CPU’s run-queue, the scheduler chooses the most appropriate thread to do the next operation which keeps the queue of one CPU is not much longer than others’. 

At first, OSv doesn't have multiple spaces. OSv runs an application with the kernel and threads sharing a single space. It means the threads and kernel use the same tables, which make system calls as efficient as function calls and also make context switches quicker. Also, because OSv shares a single address space, it doesn't maintain different permissions for the kernel and applications. Therefore, the isolation is managed by the hypervisor.

For performance, when OSv calls down to the data, it shares a single address space and avoids context switches. Also, by using the “channel”, OSv saves much processes in the traditional networking stack. OSv avoids the socket locks and TCP/IP locks. According to the performance result, the network stack’s performance for TCP and UDP consistently outperforms Linux and latency is about 25% less than Linux. Also, the context switching (thread switching) is much faster in OSv than in Linux - between 3 and 10 times faster.
